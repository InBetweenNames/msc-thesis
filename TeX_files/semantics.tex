\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter {Event-Based Semantics}

\section{Event-Based Triplestores}

One problem with entity-based triplestores is that it is difficult to add contextual information to a triple.  Two common examples of contextual information are time and location.  Many approaches that allow this use a method called {\em reification} \cite{?}.

One form of reification is to organize information into {\em events}.

\begin{definition}[Event]
	A point in time and the physical occurrences that are associated with it \cite{?} -- TODO: find better definition
\end{definition}

For example, the triple \texttt{(sally, met, susan)} in an entity-based triplestore could be represented by three triples:

\begin{code}
	(event1, type, meet)
	(event1, subject, sally)
	(event1, object, susan)
\end{code}

These triples describe the event in which ``Sally met Susan'' rather than directly describing the meeting itself.  The advantage of this approach is that it is possible to add additional information about the meeting by simply adding more triples with \texttt{event1} as the {\em subject}:

\begin{code}
	(event1, year, 1955)
	(event1, location, windsor)
\end{code}

Triplestores that organize their information in this fashion are called {\em Event-based Triplestores}.

\begin{definition}[Event-Based Triplestore]
	A triplestore where the \texttt{subject} of the triples contained within it refer to Events\cite{frostagboola2014}
\end{definition}

The key motivation behind using Event-based triplestores in this Thesis is that they directly support reification on triples\cite{frostagboola2014}.

\section{Original Event-Based Denotational Semantics}

The semantics in this Thesis is based on work that was originally described in \cite{frost2013event}.  That work was later improved upon in \cite{frostagboola2014}.

One key feature of the original semantics is that they were not tied to any particular implementation of an event-based triplestore,
removing the need to directly convert queries into corresponding triplestore queries.
This was achieved by defining the semantic functions in terms of an abstract triplestore {\em interface}.
The original semantic functions themselves were defined in pure math notation, suitable for implementation in any sufficiently powerful programming language.

In \cite{frostagboola2014}, a Miranda implementation of the semantics was demonstrated, and in \cite{frost2014denotational} a Haskell
implementation was produced as well.  A summary of the Haskell implementation is provided below:

\subsection{Triplestore interface}

Triplestore access was implemented for in-program triplestores through the following functions:

\begin{code}
	getts_1 ("?",b,c)   = [x | (x,y,z) <- ev_data, y == b, z == c]
	getts_2 (a,"?",c)   = [x | (x,y,z) <- ev_data, x == a, z == c]
	getts_3 (a,b,"?")   = [z | (x,y,z) <- ev_data, x == a, y == b]
\end{code}

Other useful triplestore functions were defined in terms of the \texttt{getts_*}
functions:

\begin{code}
	get_subj_for_ev ev       = getts_3 (ev,  "subject","?")
	get_subjs_for_events evs = concatMap (get_subj_for_event evs)
	
	get_members set = get_subjs_for_evs evs
	where
		evs = intersect evs_of_type_membership evs_with_set_as_object
		evs_of_type_membership   = getts_1 ("?", "type", "membership")
		evs_with_set_as_object   = getts_1 ("?",  "object",  set)
		
	get_subjs_of_event_type et  = get_subjs_for_evs evs
	where
		evs = getts_1 ("?",  "type",  et)
\end{code}

\subsection{Semantic functions}

Common nouns were defined as ``the set of entities that are members of the set associated with that noun'' \cite{frost2014denotational}.
These were implemented using the \texttt{get\_members} function.

\begin{code}
	person = get_members "person"
\end{code}

Intransitive verbs were defined as ``the set of entities that are subjects of an event of the type associated with that verb'' \cite{frost2014denotational}.
They were implemented using the \texttt{get\_subjs\_of\_event\_type} function.

\begin{code}
	steal = get_subjs_of_event_type "steal_ev"
\end{code}

Proper nouns were defined as ``functions that take a set of entities as an
argument and which return True if a particular entity is a member of that
set''\cite{frost2014denotational}.  They were implemented using the
\texttt{member} function which tests list membership.

\begin{code}
	torrio setofents  = "torrio" `member` setofents
\end{code}

Determiners were defined as functions taking two sets of entities, called
a nounphrase and verbphrase respectively.  Each of these functions
is defined in terms of set intersection.  They were implemented using
list intersection:

\begin{code}
  a     nph vbph     = length (intersect nph vbph) /= 0
  one   nph vbph     = length (intersect nph vbph)  == 1
  two   nph vbph     = length (intersect nph vbph)  == 2
  every nph vbph     = subset  nph vbph
\end{code}

Conjoiners for common nouns were defined similarly:

\begin{code}
  nounand s t  = intersect s t
  nounor  s t  = mkset (s ++ t) -- behaves like set union
  that         = nounand
\end{code}

Conjoiners for proper nouns and determiner phrases (a determiner
with a common noun applied to it) were implemented differently:

\begin{code}
  termand tmph1 tmph2 setofents =  (tmph1 setofents) && (tmph2 setofevs)
  termor  tmph1 tmph2 setofents =  (tmph1 setofents) || (tmph2 setofevs)
\end{code}

This was necessary because common nouns were sets of entities, but
proper nouns and determiner phrases were functions that acted on sets
of entities.

Transitive verbs were defined in terms of {\em images}.  Briefly, images
are constructed from binary relations with the \texttt{collect} function.

\begin{definition}[Collect function]
The function collect is defined such that it takes a binary relation as an
argument, joinrel, and ``returns a new binary relation, containing one binary tuple
(x, image\_x) for each member of the projection of the left-hand column of joinrel
, where image\_x is the mathematical image of x under the relation joinrel''
\end{definition}

\begin{definition}[Image]
  A function that maps elements in the domain to sets
\end{definition}

Intuitively speaking, the \texttt{collect} function converts arbitary binary
relations into functions.  $\forall x$ All pairs $(x, y_1), (x, y_2), ..., (x,
y_n)$ are grouped into one pair $(x, {y_1, y_2, ..., y_n})$ in the new binary
relation.

In the Haskell implementation, binary relations are represented with association
lists.

\begin{definition}[Entity-event relation]
  A binary relation from entities in a triplestore to events in that triplestore
\end{definition}

The function \texttt{make\_image} creates
an entity-event relation from a given event type and then converts it to an
image using \texttt{collect}:

\begin{code}
  make_image et = collect [(subj, ev) | ev <- evs, subj <- getts_3 (ev, "subject","?") ]
    where evs = getts_1 ("?", "type",  et)
\end{code}

Transitive verbs are defined by {\em filtering} tuples in the image of the event
type that corresponds to the verb based on a termphrase (proper noun or
determiner phrase) provided.  The only tuples remaining in the image are those
for which the termphrase predicate returns \texttt{True}.  An example is the
``join'' verb:

\begin{code}
  join tmph = [subj | (subj, evs) <- make_image "join_ev",
       tmph (concat [getts_3 (ev,  "object", "?") | ev <- evs])]
\end{code}

Prepositional phrases were defined through an extension of the above
mechanism.  Before passing an entity list to a termphrase, the events
those entities were drawn from would be first filtered through a series
of prepositions.

Prepositions were defined as a pair consisting of the name of a property
of an event and a termphrase.  Chained prepositional phrases were defined
as a list of prepositions.

An example chained prepositional phrase: \texttt{[("with\_implement", a
telescope), ("year", year "1877")]}

\texttt{join} could be modified to support prepositions as
follows:

\begin{code}
  joinâ€™ tmph preps = [subj | (subj, evs) <- make_image "join_ev", 
    tmph (concat [getts_3 (ev,"object","?") | ev <- evs,
      filter_ev ev preps])]
\end{code}

where \texttt{filter\_ev} is defined as follows:

\begin{code}
  filter_ev ev [] = True
  filter_ev ev (prep:list_of_preps) = ((snd (prep)) (getts_3 (ev,fst (prep),"?")))
                                      && filter_ev ev list_of_preps
\end{code}

\subsection{Haskell implementation for SPARQL}

Later, in \cite{agboola2015extensible}, the Haskell implementation was modified
to support SPARQL endpoints with some efficiency improvements.  In particular, the asymptotic time complexity of the \texttt{collect} function was improved to O$(n$ log $n)$ time.

\section{Improvements over Original Semantics}

The improvements from the original semantics presented in \cite{frost2014demonstration} \cite{frostagboola2014} are detailed below.


\subsection{Naming and definition of ``Images''}

Originally, some semantic functions were defined in terms of {\em images}.

In this Thesis, we refer to these structures as... 

\subsection{Semantic consistency}

NOTE: definition of get\_members, etc, different! get\_members returns an Image, not a list of entities!

\subsection{Type safety}

\subsection{The implicit `and' problem}

In the original semantics there was a problem with how prepositional phrases were implemented.  Namely, an implicit ``and'' was placed in between
each preposition, transforming sentences such as ``who discovered a moon with a telescope in 1877 at us\_naval\_observatory'' into ``who discovered a moon with a telescope and in 1932 and at us\_naval\_observatory''.

In the above example, the meanings of both sentences are identical, however when determiners such as ``one'', ``two'', and ``every'' are used, the meaning changes:

%TODO: Fix
TODO: Fix example
``who discovered a moon with two telescopes in 1877''.  In this example, ``hall'' both discovered a moon with two telescopes and also discovered a moon
in 1877, but the two moons were not the same moon.  Therefore the result set should be empty, however because the sentence was treated as
``who discovered a moon with two telescopes and in 1877'', it was nonempty, leading to a misleading result.

It turns out there was a specific property that enabled a determiner to work:

This was fixed by modifying \texttt{filter\_ev} as follows:

This worked because all termphrases are based on the function \texttt{intersect\_entevimages}, which acts as a list intersection.
Therefore, each termphrase returns exactly the events which are relevant.  So the resultant list obtained from \texttt{tmph list}
can be used against the remaining prepositions, recursively.


\subsection{The use of `by' as a preposition}

One item of note is that in our semantics we treat the word ``by'', as in ``discovered\_by'', as a preposition.

We noticed that the function to process the word ``by'' and the function to filter events based on prepositions were nearly 
identical, with the former being a special case of the latter.

\subsection{Efficiency}

The \texttt{collect} function as defined in \cite{agboola2015extensible} used a key-value store from the \texttt{Data.Map.Lazy} module in Haskell to efficiently construct Images from relations represented as association lists.  Because all key-value pairs of the \texttt{Map} will eventually be traversed, in this Thesis the \texttt{Data.Map.Strict} module was used instead.  The asymptotic time complexity of both methods are identical, however the \texttt{Strict} version uses less memory and is slightly faster as it does not attempt to store partially evaluated areas of the Map as {\em thunks}.

%\begin{theorem}
%	\texttt{collect} is optimal.
%\end{theorem}

%Proof: Suppose a function \texttt{collect'} exists that converts a relation into an Image in faster than O($n$ lg $n$) time.

%Let $unsorted$ be an unsorted list whose list elements are an instance of the \texttt{Comparable} typeclass.
%That is, the list elements can be compared with one another using the comparison operators.

%Define the function \texttt{sort'} as follows:

%\begin{code}
%	sort' = uncollect . collect'
%	where
%	uncollect = map (\(ent, evs) -> map (\ev -> (ent, ev)) evs)
%\end{code}

\subsubsection{Constructing Images from grouped association lists}
In addition, a new function, \texttt{condense}, is defined to efficiently construct Images from relations implemented using association lists that are grouped according to the first element in each pair.

\begin{code}
	condense = map (\list -> (fst $ head list, map snd list)) . List.groupBy cmp
	where
	cmp x y = (fst x) == (fst y)
\end{code}

\begin{theorem}
	\texttt{condense} has $O(n)$ worst-case upper-bound asymptotic time complexity, with comparison on the first element in the association list pairs being the key operation.
\end{theorem}

Proof:

\texttt{cmp} is the function that compares two association list pairs by their first element.  

%\begin{proposition}
%	\texttt{cmp} has $O(1)$ worst-case upper-bound asymptotic time complexity, with comparison being the key operation.
%\end{proposition}

%Proof:

%In the Haskell standard library source code, \texttt{fst} is defined as follows \cite{hstdlib}:

%\begin{code}
%	fst (x,_) = x
%\end{code}

%This function has trivially $\theta(1)$ worst-case tight bound time complexity for any key operation.

%Since Haskell is a pass-by-reference language with lazy evaluation, this function will return in a constant amount of time regardless of the size of \texttt{x},
%as \texttt{x} will not be copied on return of the function.  Therefore \texttt{fst} has $\theta(1)$ worst-case tight bound time complexity.

%The operator \texttt{(==)} for the \texttt{String} type (triples are represented as 3-tuples of \texttt{Strings} in our code) has a worst-case upper bound time %complexity of O$(n)$, because in the worst case, both \texttt{Strings} being compared have length $n$ and are equal, forcing each character in both strings to be %evaluated and compared.

%Only one comparison on the first elements of the pairs \texttt{x} and \texttt{y} is performed for \texttt{cmp x y}.
%Therefore, the worst-case upper-bound asymptotic time complexity of \texttt{cmp} is O$(1)$.

%Since the $O(n)$ term dominates for large $n$, \texttt{cmp} therefore has a worst-case tight-bound asymptotic time complexity of $O(n)$. \qedsymbol

\begin{proposition}
	The function \texttt{List.groupBy cmp} has O$(n)$ worst-case upper-bound asymptotic time complexity, with comparisons on the elements of the input list using \texttt{cmp} being the key operation.
\end{proposition}

Proof:

In the Haskell standard library source code, \texttt{Data.List.groupBy} is defined as follows: \cite{hstdlib}:

\begin{code}
	groupBy _  []           =  []
	groupBy eq (x:xs)       =  (x:ys) : groupBy eq zs
	where (ys,zs) = span (eq x) xs
\end{code}

\texttt{span} is defined as follows \cite{hstdlib}:

\begin{code}
	span _ xs@[]            =  (xs, xs)
	span p xs@(x:xs')
	| p x          =  let (ys,zs) = span p xs' in (x:ys,zs)
	| otherwise    =  ([],xs)
\end{code}

%\begin{subproposition}
%	\texttt{span} has O$(n)$ worst case tight bound asymptotic time complexity, with evaluations of predicate \texttt{p} being the key operation.
%\end{subproposition}

%Proof:

%In the worst case, \texttt{p} will evaluate to \texttt{True} for all elements in the input list \texttt{xs}, forcing
%the evaluation of \texttt{span} on all suffixes of \texttt{xs}.  Since there are $n + 1$ suffixes of \texttt{xs}, 
%and \texttt{p} is evaluated for each suffix, it follows that $n + 1$ evaluations of \texttt{p} are performed.
%Therefore, \texttt{span} has a worst-case lower-bound asymptotic time complexity of O$(n + 1) = $O$(n)$. \qedsymbol

%--

Here, \text{eq = cmp} in \texttt{groupBy}, with \texttt{eq x = cmp x = p} being the predicate function used in \texttt{span}. %for elements of the list \text{(x:xs)}.

%The $0$th contiguous group of elements in a list \texttt{qs} according to a predicate \texttt{pred} is the longest prefix \texttt{pre} of \texttt{qs} where
%\texttt{pred} is \texttt{True} for all elements in \texttt{pre}.

%The $i$th contiguous group of elements in a list \texttt{qs} according to a predicate \texttt{pred} is the $0$th contiguous group of elements of
%the list obtained by removing all previous contiguous groups of elements from \texttt{qs}. 

%The $i$th contiguous group of elements in a list \texttt{qs} according to a predicate \texttt{pred} is the longest prefix \texttt{pre} of the list \texttt{rs}
%where \texttt{rs} is the list obtained by removing all previous contiguous groups of elements from \texttt{qs}, and \texttt{pred} is \texttt{True} for all elements
%of \texttt{pre}.

%A contiguous group of elements in a list \texttt{qs} under a predicate \texttt{pred} is a contiguous sublist of \texttt{qs} such that \texttt{pred}
%is \texttt{True} for all elements in the sublist.

%Let $m$ be the number of contiguous groups of elements in the list \texttt{(x:xs)}.

%Let $C$ be the list containing the number of elements in each contiguous group of elements in the list \texttt{(x:xs)}.  \texttt{C[i]} denotes the \texttt{i}th element in \texttt{C}.

Let $n$ denote the number of elements in \texttt{(x:xs)}.

The function \texttt{span} returns a partition \texttt{(ys, zs)} of the input list \texttt{xs}, where \texttt{ys} is the longest prefix of \texttt{xs} such that predicate \texttt{p} is \texttt{True} on all elements in the prefix, and \texttt{zs} are the remaining elements in \texttt{xs}.  It follows that \texttt{p} is evaluated at least $s$ times and at most $s + 1$ times, where $s$ is the length of \texttt{pre} (it will only be evaluated $s$ times if \texttt{pre = xs}).

By recursing into the second list returned by \texttt{span}, no previous elements of \texttt{(x:xs)} are revisited, and no elements are skipped, so \texttt{groupBy} partitions the input list \texttt{(x:xs)} into $m$ lists.  Call this partition \texttt{part}.  Note that the sum of the lengths of all lists in \texttt{part} is $n$.

For each list \texttt{i} in \texttt{part} except the last, \texttt{(length i - 1) + 1 = length i} comparisons will have been made (\texttt{groupBy} calls span on \texttt{xs}, not \texttt{x:xs}).  For the last list $last$ in \texttt{part}, \texttt{(length last - 1)} comparisons will have been made (the longest prefix is \texttt{xs} in this case).  Therefore, the total number of comparisons made can be expressed by:

\begin{code}
length part[0] + length part[1] + ... + length part[m - 2] + (length part[m - 1] - 1)
= (length part[0] + length part[1] + ... + length part[m - 1]) - 1
= n - 1
\end{code}

Hence, the worst-case upper-bound asymptotic time complexity of \texttt{List.groupBy cmp} is O$(n - 1)$ = O$(n)$, with comparisons using \texttt{cmp} being the key operation.
\qedsymbol

--

The lambda provided to \texttt{map} performs no comparisons and therefore has a worst-case tight-bound time complexity of
$\theta(1)$ with comparisons being the key operation.

The same applies to the composition function $\circ$.

--

%Let \texttt{groupPair list = (fst \$ head list, map snd list)}.

%\begin{proposition}
%	groupPair has O$(n)$ time complexity
%\end{proposition}

%Proof:

%\texttt{head list} has a worst-case tight-bound time complexity of $\theta(1)$.

%\texttt{snd} has a worst-case tight-bound time complexity of $\theta(1)$.

%\texttt{map} evaluates \texttt{snd} on every element of \texttt{list}, with
%a worst-case tight-bound time complexity of $\theta(n)*\theta(1) = \theta(n)$ .
%--

%\texttt{groupPair} and the lambda used in \texttt{map} used above have an identical definition and therefore have
%the same asymptotic time complexity.

The \texttt{map} function is composed with the \texttt{List.groupBy cmp} function to produce a new function:
\begin{code}
	\x -> map (\list -> (fst $ head list, map snd list)) (List.groupBy cmp x)
\end{code}

The \texttt{map} function evaluates the lambda over every list in the partition returned by (List.groupBy cmp x).  Since
neither the map, the lambda, nor the function composition perform any comparisons, they do not contribute to the number
of key operations performed.

Therefore the worst-case upper bound time complexity of \texttt{condense} is $O(1) + n*(O(1) + O(1)) + O(n) = O(n)$ with comparison on the first element in
the association list pairs (\texttt{cmp}) being the key operation.
$\blacksquare$

%Since \texttt{condense} has a worst-case tight bound asymptotic time complexity of $\theta(n)$, it is optimal. \qedsymbol 

\end{document}
