\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter {Event-Based Semantics}

\section{Event-Based Triplestores}

One problem with entity-based triplestores is that it is difficult to add contextual information to a triple.  Two common examples of contextual information are time and location.  Many approaches that allow this use a method called {\em reification} \cite{?}.

One form of reification is to organize information into {\em events}.

\begin{definition}[Event]
	A point in time and the physical occurrences that are associated with it \cite{?} -- TODO: find better definition
\end{definition}

For example, the triple \texttt{(sally, met, susan)} in an entity-based triplestore could be represented by three triples:

\begin{code}
	(event1, type, meet)
	(event1, subject, sally)
	(event1, object, susan)
\end{code}

These triples describe the event in which ``Sally met Susan'' rather than directly describing the meeting itself.  The advantage of this approach is that it is possible to add additional information about the meeting by simply adding more triples with \texttt{event1} as the {\em subject}:

\begin{code}
	(event1, year, 1955)
	(event1, location, windsor)
\end{code}

Triplestores that organize their information in this fashion are called {\em Event-based Triplestores}.

\begin{definition}[Event-Based Triplestore]
	A triplestore where the \texttt{subject} of the triples contained within it refer to Events\cite{frostagboola2014}
\end{definition}

The key motivation behind using Event-based triplestores in this Thesis is that they directly support reification on triples\cite{frostagboola2014}.

\section{Original Event-Based Denotational Semantics}

The semantics in this Thesis is based on work that was originally described in \cite{frost2013event}.  That work was later improved upon in \cite{frostagboola2014}.

One key feature of the original semantics is that they were not tied to any particular implementation of an event-based triplestore,
removing the need to directly convert queries into corresponding triplestore queries.
This was achieved by defining the semantic functions in terms of an abstract triplestore {\em interface}.
The original semantic functions themselves were defined in pure math notation, suitable for implementation in any sufficiently powerful programming language.

In \cite{frostagboola2014}, a Miranda implementation of the semantics was demonstrated, and in \cite{frost2014denotational} a Haskell
implementation was produced as well.  In both the Miranda and Haskell versions, the sets used in the semantics were represented using
singly-linked lists, called {\em lists}.  Lists are composed using the \texttt{(:)} operator, where the left argument of \texttt{(:)} is an element
and the right argument is a list.  The \texttt{(:)} operator is {\em right-associative} prepends the left operand to the right operand.  The empty list is denoted with
\texttt{[]}.  The syntax \texttt{[x\_1, x\_2, ... x\_n]}, \texttt{(x\_1 : x\_2 : ... : x\_n : [])} and \texttt{(x\_1 : (x\_2 : ... : (x\_n : [])))} are equivalent.
Lists are homogeneous in that types of all elements in the list must be identical.

A summary of the original semantics and the Haskell implementation is provided below:

\subsection{Triplestore interface}

Triplestore access was implemented for in-program triplestores through the following functions, where
\texttt{ev\_data} is an in-program triplestore represented as a list of 3-tuples, each 3-tuple representing a triple:

\begin{code}
	getts_1 ("?",b,c)   = [x | (x,y,z) <- ev_data, y == b, z == c]
	getts_2 (a,"?",c)   = [x | (x,y,z) <- ev_data, x == a, z == c]
	getts_3 (a,b,"?")   = [z | (x,y,z) <- ev_data, x == a, y == b]
\end{code}

Other useful triplestore functions were defined in terms of the \texttt{getts\_*}
functions:

\begin{code}
	get_subj_for_ev ev       = getts_3 (ev,  "subject","?")
	get_subjs_for_events evs = concatMap (get_subj_for_event evs)
	
	get_members set = get_subjs_for_evs evs
	where
		evs = intersect evs_of_type_membership evs_with_set_as_object
		evs_of_type_membership   = getts_1 ("?", "type", "membership")
		evs_with_set_as_object   = getts_1 ("?",  "object",  set)
		
	get_subjs_of_event_type et  = get_subjs_for_evs evs
	where
		evs = getts_1 ("?",  "type",  et)
\end{code}

\subsection{Semantic functions}

Common nouns were defined as ``the set of entities that are members of the set associated with that noun'' \cite{frost2014denotational}.
These were implemented using the \texttt{get\_members} function.

NOTE: Should the code examples be rewritten to not use anything from \cite{frost2014denotational}?
\begin{code}
	person = get_members "person"
\end{code}

Intransitive verbs were defined as ``the set of entities that are subjects of an event of the type associated with that verb'' \cite{frost2014denotational}.
They were implemented using the \texttt{get\_subjs\_of\_event\_type} function.

\begin{code}
	steal = get_subjs_of_event_type "steal_ev"
\end{code}

Proper nouns were defined as ``functions that take a set of entities as an
argument and which return True if a particular entity is a member of that
set''\cite{frost2014denotational}.  They were implemented using the
\texttt{member} function which tests list membership.

\begin{code}
	torrio setofents  = "torrio" `member` setofents
\end{code}

Determiners were defined as functions taking two sets of entities, called
a nounphrase and verbphrase respectively.  Each of these functions
is defined in terms of set intersection.  They were implemented using
list intersection:

\begin{code}
  a     nph vbph     = length (intersect nph vbph) /= 0
  one   nph vbph     = length (intersect nph vbph)  == 1
  two   nph vbph     = length (intersect nph vbph)  == 2
  every nph vbph     = subset  nph vbph
\end{code}

Conjoiners for common nouns were implemented similarly:

\begin{code}
  nounand s t  = intersect s t
  nounor  s t  = mkset (s ++ t) -- behaves like set union
  that         = nounand
\end{code}


A {\em determiner phrase} was defined as being a determiner with a common noun applied to it \cite{frost2014denotational}.
A {\em termphrase} was defined as being either a a proper noun or a determiner phrase \cite{frost2014denotational}.
Conjoiners for termphrases were implemented differently:

\begin{code}
  termand tmph1 tmph2 setofents =  (tmph1 setofents) && (tmph2 setofevs)
  termor  tmph1 tmph2 setofents =  (tmph1 setofents) || (tmph2 setofevs)
\end{code}

This was necessary because common nouns were sets of entities, but
proper nouns and determiner phrases were functions that acted on sets
of entities.

Transitive verbs were defined in terms of {\em images} \cite{frost2014denotational}.  Briefly, images
are constructed from binary relations with the \texttt{collect} function.

\begin{definition}[Collect function]
The function collect is defined such that it takes a binary relation as an
argument, joinrel, and ``returns a new binary relation, containing one binary tuple
(x, image\_x) for each member of the projection of the left-hand column of joinrel
, where image\_x is the mathematical image of x under the relation joinrel'' \cite{frost2014denotational}
\end{definition}

\begin{definition}[Image]
  A function that maps elements in the domain to sets
\end{definition}

Intuitively speaking, the \texttt{collect} function converts arbitrary binary
relations into functions.  $\forall x$ All pairs $(x, y_1), (x, y_2), ..., (x,
y_n)$ are grouped into one pair $(x, {y_1, y_2, ..., y_n})$ in the new binary
relation.

In the Haskell implementation, binary relations and images were represented using {\em association
lists}, which are lists of pairs\cite{frost2014denotational}.

\texttt{collect} was implemented as follows:

\begin{code}
collect [] = []
collect ((x,y):t) = (x, y:[e2 |(e1, e2)<-t,e1 == x]): collect [(e1, e2) | (e1, e2) <- t, e1 /= x ]
\end{code}

According to \cite{agboola2015extensible}, this implementation of \texttt{collect} has a worst-case asymptotic time complexity of
O$(n^2)$.

\begin{definition}[Entity-event relation]
  A binary relation from entities in a triplestore to events in that triplestore
\end{definition}

The function \texttt{make\_image} creates an entity-event relation from a given event type and then converts it to an image using \texttt{collect}:

\begin{code}
  make_image et = collect [(subj, ev) | ev <- evs, subj <- getts_3 (ev, "subject","?") ]
    where evs = getts_1 ("?", "type",  et)
\end{code}

Transitive verbs were defined by {\em filtering} pairs in the image of the event
type that corresponds to the verb using the termphrase provided.  The only pairs remaining in the image are those
for which the termphrase predicate returns \texttt{True}.  An example is the
``join'' verb:

\begin{code}
  join tmph = [subj | (subj, evs) <- make_image "join_ev",
       tmph (concat [getts_3 (ev,  "object", "?") | ev <- evs])]
\end{code}

Prepositional phrases were defined through an extension of the above
mechanism.  Before passing an entity list to a termphrase, the events
those entities were drawn from would be first filtered through a series
of prepositions.

Prepositions were defined as a pair consisting of the name of a property
of an event and a termphrase.  Chained prepositional phrases were defined
as a list of prepositions.

An example chained prepositional phrase: \texttt{[("with\_implement", a
telescope), ("year", year "1877")]}

\texttt{join} could be modified to support prepositions as
follows:

\begin{code}
  joinâ€™ tmph preps = [subj | (subj, evs) <- make_image "join_ev", 
    tmph (concat [getts_3 (ev,"object","?") | ev <- evs,
      filter_ev ev preps])]
\end{code}

where \texttt{filter\_ev} is defined as follows \cite{frost2014denotational}:

\begin{code}
  filter_ev ev [] = True
  filter_ev ev (prep:list_of_preps) = ((snd (prep)) (getts_3 (ev,fst (prep),"?")))
                                      && filter_ev ev list_of_preps
\end{code}

\subsection{Haskell implementation for SPARQL}

Later, in \cite{agboola2015extensible}, the Haskell implementation was modified
to support SPARQL endpoints, with some efficiency improvements.  In particular, the asymptotic time complexity of the \texttt{collect} function was improved to O$(n$ log $n)$ time.

\section{Improvements over Original Semantics}

The improvements from the original semantics presented in \cite{frost2014demonstration} \cite{frostagboola2014} are detailed below.

\subsection{Naming and definition of ``Images''}

Originally, transitive verbs were defined in terms of {\em images} \cite{frost2014denotational}.
In this Thesis, we use the term {\em function defined by the relation} instead of {\em image}, as {\em image} is a term that already exists throughout mathematics and has
a different meaning.

\begin{definition}[Function defined by the relation $r$]
	The function defined by the binary relation $r$ is the set $\{(x, image_x) : x $ is a member of the domain of $r$ and $image_x$ is the image of $x$ under $r\}$
\end{definition}

The function defined by a relation is referred to throughout this thesis by the shorthand {\em FDBR}.  It is represented with an association list in the Haskell code,
as {\em images} were represented in the original semantics.  The function defined by the relation $r$ is denoted with the syntax $FDBR(r)$.

\subsection{Semantic consistency}

NOTE: definition of get\_members, etc, different! get\_members returns an FDBR, not a list of entities!

In the original semantics...

Mention new definition for prepositions, use of ``in''

\subsection{Type safety}

The original semantics were implemented as {\em pure functions} in Haskell, which was acceptable for the in-program triplestores they were used on.

In \cite{agboola2015extensible}, the \texttt{getts\_*} functions were modified to retrieve triples from external SPARQL endpoints, enabling the original
semantics to work with SPARQL triplestores.  For SPARQL triplestores, however, the \texttt{getts\_*} functions as defined in \cite{agboola2015extensible} are not actually guaranteed to be referentially transparent. In particular, SPARQL triplestores are able to change over time with triples being potentially added, removed, or modified.
For example, consider the query ``which people discovered a moon that was discovered by a person''.
``people'' and ``person'' are synonyms in our semantics and therefore the same query would be performed twice.  If the SPARQL triplestore changed in between these evaluations,
then these queries could return different results, violating referential transparency.

In order to maintain compatibility with the original semantics, the function \texttt{unsafeDupablePerformIO} was used in \cite{agboola2015extensible} to force Haskell to treat the \texttt{getts\_*} functions as pure functions.

The problem with \texttt{unsafeDupablePerformIO} is that it subverts the type system of Haskell.  Code that is built using it is therefore not on
solid theoretical ground within the constructs of the language, and surprising effects can occur as a result.  The use of \texttt{unsafeDupablePerformIO}, while
legitimate in some cases, is heavily discouraged within the Haskell community \cite{noUnsafePerformIO}.

In this Thesis, we chose a different approach to handling external triplestore queries by representing the triplestore functions and semantics in terms of {\em monadic functions}.
Briefly, monads in the {\em Haskell} programming language are types that are instances of the {\em Monad} typeclass that obey the
{\em monad laws}.  In the Haskell programming language, functions that are not {\em referentially transparent} are represented using computations in the monad \texttt{IO}, commonly referred to as the {\em IO monad}.  By expressing the semantics and triplestore functions monadically, we stay safely within the confines of Haskell's type system, avoiding
the need to use \texttt{unsafeDupablePerformIO} in order to perform queries to external triplestores as a result.  Another key benefit of this approach is that it preserves the compositional nature of the original semantics.

The semantics are defined in the IO monad currently, however if other monads were desired, only minimal changes would be required in order to accommodate
other instances of the Monad typeclass for the semantics.  In {\em Future Work}, one potential application of this functionality is discussed.

\subsection{The implicit `and' problem and the problem of `every'}

In the original semantics there were two problems with how prepositional phrases were implemented.

First, a query such as ``the sun is orbited by every planet'' would have returned \texttt{False} due to the way \texttt{filter\_ev} was implemented.

This was because in $FDBR($\texttt{orbit\_}$)$, where \texttt{orbit\_} is the entity-event relation defined by the event type ``orbit\_ev'' in the triplestore, with the \texttt{objects} of those events forming the entities,
the pair for \texttt{sun} would look like: \texttt{(sun, [event1000, event1001, ..., event1008])}, where each event would denote a separate \texttt{orbit} event corresponding to each planet.
\texttt{filter\_ev} applied each preposition's termphrase to each event separately, meaning that no information provided by other events could be used by the predicate.  Therefore \texttt{every planet}
would have returned \texttt{False} on each individual event, and \texttt{filter\_ev} would have discarded the pair for \texttt{sun} in $FDBR($\texttt{orbit\_}$)$.  If there were one singular orbit event in which all of the
planets were listed as orbiting the sun, then this query would have worked, however, it may not be reasonable to expect event-based triplestores to organize their information in this fashion in practice--especially if there are properties unique to each planet that are being described in each orbit event.
This was fixed by modifying \texttt{filter\_ev} to first collect all of the relevant properties for each preposition from all events,  and then evaluating the termphrase over those properties.
 
Second, an implicit ``and'' was placed in between each preposition, transforming sentences such as ``who discovered something with two telescopes in 1914'' into ``who discovered something with two telescopes and in 1914''.

Although the above sentence is ambiguous in that it could be asking whether someone used two telescopes to discover one particular object, or whether
someone discovered potentially different objects with two telescopes, the asker most certainly did not intend for an implicit ``and'' to be inserted in between the prepositions.

The reason this happens is because in the original \texttt{filter\_ev} function, the event lists were not actually ``honed down'' before being passed to subsequent predicates in the preposition chain.

Both of these problems were solved by modifying \texttt{filter\_ev} as follows:

\begin{code}
	filter_ev :: (TripleStore m) => m -> [([String], IO FDBR -> IO FDBR)] -> [Event] -> IO Bool
	filter_ev _ [] _ = return True
	filter_ev ev_data ((names,pred):list) evs = do
		relevant_list <- mapM (\name -> getts_preimage ev_data name evs) names
		res <- pred $ return $ concat $ relevant_list
		let relevant_evs = List.nub $ concatMap snd res
		if res /= [] then filter_ev ev_data list relevant_evs else return False
\end{code}

Briefly, \texttt{filter\_ev} creates an FBDR out of the provided event list \texttt{evs} by using the \texttt{getts\_preimage} function
to ``pull out'' the desired property names from an event list (prepositions may have multiple property names).  All of these are merged into one FDBR
which the termphrase associated with the preposition is then evaluated on.  Termphrases always return only the elements of an FBDR that are ``relevant'',
as all termphrases are defined in terms of the function \texttt{intersect\_entevimages}, which behaves like a list intersection except for FDBRs.
So the resultant list \texttt{res} can be used against the remaining prepositions, recursively, ``honing down'' the relevant events on each preposition
in the chain.

The ambiguity noted above with the use of ``every'' could potentially be solved in the future by introducing a new word ``using''.  ``who discovered something with two telescopes in 1914'' would then
mean that someone discovered could have discovered multiple objects with two telescopes, and ``who discovered something using two telescopes in 1914'' would mean that someone discovered one particular object using two telescopes.

\subsection{The use of `by' as a preposition}

One item of note is that in our semantics we treat the word ``by'', as in ``discovered\_by'', as a preposition.

We noticed that the function to process the word ``by'' and the function to filter events based on prepositions were nearly 
identical, with the former being a special case of the latter.

\subsection{Efficiency}

The \texttt{collect} function as defined in \cite{agboola2015extensible} used a key-value store from the \texttt{Data.Map.Lazy} module in Haskell to efficiently construct Images from relations represented as association lists.  Because all key-value pairs of the \texttt{Map} will eventually be traversed, in this Thesis the \texttt{Data.Map.Strict} module was used instead.  The asymptotic time complexity of both methods are identical, however the \texttt{Strict} version uses less memory and is slightly faster as it does not attempt to store partially evaluated areas of the Map as {\em thunks}.

%\begin{theorem}
%	\texttt{collect} is optimal.
%\end{theorem}

%Proof: Suppose a function \texttt{collect'} exists that converts a relation into an Image in faster than O($n$ lg $n$) time.

%Let $unsorted$ be an unsorted list whose list elements are an instance of the \texttt{Comparable} typeclass.
%That is, the list elements can be compared with one another using the comparison operators.

%Define the function \texttt{sort'} as follows:

%\begin{code}
%	sort' = uncollect . collect'
%	where
%	uncollect = map (\(ent, evs) -> map (\ev -> (ent, ev)) evs)
%\end{code}

\subsubsection{Efficiently constructing FDBRs from grouped association lists}
In addition, a new function, \texttt{condense}, has been created to efficiently construct $FDBR(r)$ such that $r$ is represented by an association list that is grouped according to the first element in each pair.

\begin{code}
	condense = map (\list -> (fst $ head list, map snd list)) . List.groupBy cmp
	where
	cmp x y = (fst x) == (fst y)
\end{code}

\begin{theorem}
	\texttt{condense} has $O(n)$ worst-case upper-bound asymptotic time complexity, with comparison on the first element in the association list pairs being the key operation.
\end{theorem}

Proof:

\texttt{cmp} is the function that compares two association list pairs by their first element.  

%\begin{proposition}
%	\texttt{cmp} has $O(1)$ worst-case upper-bound asymptotic time complexity, with comparison being the key operation.
%\end{proposition}

%Proof:

%In the Haskell standard library source code, \texttt{fst} is defined as follows \cite{hstdlib}:

%\begin{code}
%	fst (x,_) = x
%\end{code}

%This function has trivially $\theta(1)$ worst-case tight bound time complexity for any key operation.

%Since Haskell is a pass-by-reference language with lazy evaluation, this function will return in a constant amount of time regardless of the size of \texttt{x},
%as \texttt{x} will not be copied on return of the function.  Therefore \texttt{fst} has $\theta(1)$ worst-case tight bound time complexity.

%The operator \texttt{(==)} for the \texttt{String} type (triples are represented as 3-tuples of \texttt{Strings} in our code) has a worst-case upper bound time %complexity of O$(n)$, because in the worst case, both \texttt{Strings} being compared have length $n$ and are equal, forcing each character in both strings to be %evaluated and compared.

%Only one comparison on the first elements of the pairs \texttt{x} and \texttt{y} is performed for \texttt{cmp x y}.
%Therefore, the worst-case upper-bound asymptotic time complexity of \texttt{cmp} is O$(1)$.

%Since the $O(n)$ term dominates for large $n$, \texttt{cmp} therefore has a worst-case tight-bound asymptotic time complexity of $O(n)$. \qedsymbol

\begin{proposition}
	The function \texttt{List.groupBy cmp} has O$(n)$ worst-case upper-bound asymptotic time complexity, with comparisons on the elements of the input list using \texttt{cmp} being the key operation.
\end{proposition}

Proof:

In the Haskell standard library source code, \texttt{Data.List.groupBy} is defined as follows: \cite{hstdlib}:

\begin{code}
	groupBy _  []           =  []
	groupBy eq (x:xs)       =  (x:ys) : groupBy eq zs
	where (ys,zs) = span (eq x) xs
\end{code}

\texttt{span} is defined as follows \cite{hstdlib}:

\begin{code}
	span _ xs@[]            =  (xs, xs)
	span p xs@(x:xs')
	| p x          =  let (ys,zs) = span p xs' in (x:ys,zs)
	| otherwise    =  ([],xs)
\end{code}

%\begin{subproposition}
%	\texttt{span} has O$(n)$ worst case tight bound asymptotic time complexity, with evaluations of predicate \texttt{p} being the key operation.
%\end{subproposition}

%Proof:

%In the worst case, \texttt{p} will evaluate to \texttt{True} for all elements in the input list \texttt{xs}, forcing
%the evaluation of \texttt{span} on all suffixes of \texttt{xs}.  Since there are $n + 1$ suffixes of \texttt{xs}, 
%and \texttt{p} is evaluated for each suffix, it follows that $n + 1$ evaluations of \texttt{p} are performed.
%Therefore, \texttt{span} has a worst-case lower-bound asymptotic time complexity of O$(n + 1) = $O$(n)$. \qedsymbol

%--

Here, \text{eq = cmp} in \texttt{groupBy}, with \texttt{eq x = cmp x = p} being the predicate function used in \texttt{span}. %for elements of the list \text{(x:xs)}.

%The $0$th contiguous group of elements in a list \texttt{qs} according to a predicate \texttt{pred} is the longest prefix \texttt{pre} of \texttt{qs} where
%\texttt{pred} is \texttt{True} for all elements in \texttt{pre}.

%The $i$th contiguous group of elements in a list \texttt{qs} according to a predicate \texttt{pred} is the $0$th contiguous group of elements of
%the list obtained by removing all previous contiguous groups of elements from \texttt{qs}. 

%The $i$th contiguous group of elements in a list \texttt{qs} according to a predicate \texttt{pred} is the longest prefix \texttt{pre} of the list \texttt{rs}
%where \texttt{rs} is the list obtained by removing all previous contiguous groups of elements from \texttt{qs}, and \texttt{pred} is \texttt{True} for all elements
%of \texttt{pre}.

%A contiguous group of elements in a list \texttt{qs} under a predicate \texttt{pred} is a contiguous sublist of \texttt{qs} such that \texttt{pred}
%is \texttt{True} for all elements in the sublist.

%Let $m$ be the number of contiguous groups of elements in the list \texttt{(x:xs)}.

%Let $C$ be the list containing the number of elements in each contiguous group of elements in the list \texttt{(x:xs)}.  \texttt{C[i]} denotes the \texttt{i}th element in \texttt{C}.

Let $n$ denote the number of elements in \texttt{(x:xs)}.

The function \texttt{span} returns a partition \texttt{(ys, zs)} of the input list \texttt{xs}, where \texttt{ys} is the longest prefix of \texttt{xs} such that predicate \texttt{p} is \texttt{True} on all elements in the prefix, and \texttt{zs} are the remaining elements in \texttt{xs}.  It follows that \texttt{p} is evaluated at least $s$ times and at most $s + 1$ times, where $s$ is the length of \texttt{pre} (it will only be evaluated $s$ times if \texttt{pre = xs}).

By recursing into the second list returned by \texttt{span}, no previous elements of \texttt{(x:xs)} are revisited, and no elements are skipped, so \texttt{groupBy} partitions the input list \texttt{(x:xs)} into $m$ lists.  Call this partition \texttt{part}.  Note that the sum of the lengths of all lists in \texttt{part} is $n$.

For each list \texttt{i} in \texttt{part} except the last, \texttt{(length i - 1) + 1 = length i} comparisons will have been made (\texttt{groupBy} calls span on \texttt{xs}, not \texttt{x:xs}).  For the last list $last$ in \texttt{part}, \texttt{(length last - 1)} comparisons will have been made (the longest prefix is \texttt{xs} in this case).  Therefore, the total number of comparisons made can be expressed by:

\begin{code}
length part[0] + length part[1] + ... + length part[m - 2] + (length part[m - 1] - 1)
= (length part[0] + length part[1] + ... + length part[m - 1]) - 1
= n - 1
\end{code}

Hence, the worst-case upper-bound asymptotic time complexity of \texttt{List.groupBy cmp} is O$(n - 1)$ = O$(n)$, with comparisons using \texttt{cmp} being the key operation.
\qedsymbol

--

The lambda provided to \texttt{map} performs no comparisons and therefore has a worst-case tight-bound time complexity of
$\theta(1)$ with comparisons being the key operation.

The same applies to the composition function $\circ$.

--

%Let \texttt{groupPair list = (fst \$ head list, map snd list)}.

%\begin{proposition}
%	groupPair has O$(n)$ time complexity
%\end{proposition}

%Proof:

%\texttt{head list} has a worst-case tight-bound time complexity of $\theta(1)$.

%\texttt{snd} has a worst-case tight-bound time complexity of $\theta(1)$.

%\texttt{map} evaluates \texttt{snd} on every element of \texttt{list}, with
%a worst-case tight-bound time complexity of $\theta(n)*\theta(1) = \theta(n)$ .
%--

%\texttt{groupPair} and the lambda used in \texttt{map} used above have an identical definition and therefore have
%the same asymptotic time complexity.

The \texttt{map} function is composed with the \texttt{List.groupBy cmp} function to produce a new function:
\begin{code}
	\x -> map (\list -> (fst $ head list, map snd list)) (List.groupBy cmp x)
\end{code}

The \texttt{map} function evaluates the lambda over every list in the partition returned by (List.groupBy cmp x).  Since
neither the map, the lambda, nor the function composition perform any comparisons, they do not contribute to the number
of key operations performed.

Therefore the worst-case upper bound time complexity of \texttt{condense} is $O(1) + n*(O(1) + O(1)) + O(n) = O(n)$ with comparison on the first element in
the association list pairs (\texttt{cmp}) being the key operation.
$\blacksquare$

%Since \texttt{condense} has a worst-case tight bound asymptotic time complexity of $\theta(n)$, it is optimal. \qedsymbol 

\end{document}
