\documentclass[../main.tex]{subfiles}

\begin{document}
	
\chapter{Future Work}


\section{Providing Event-based views into entity-based triplestores}

The system presented in this Thesis requires event-based triplestores in order to function.  Much of the Semantic Web, however, is not comprised of event-based triplestores.  In order to perform queries on these databases, there must be a way to transform these existing triplestores into an event-based form or provide an event-based ``view'' into these databases. 

In practice, entity-based triplestores also contain {\em ontology} information that describes the structure of particular sets of triples.  An ontology in the Semantic Web
serves a similar purpose as a schema does in a relational database.  In fact, the original language proposed by the W3C for describing ontologies was called {\em RDF Schema}.  This evolved into what is known today as the {\em Web Ontology Language} or {\em OWL} for short.

\begin{definition}[Ontology]
	``An ontology is an explicit specification of a conceptualization''\cite{gruber}
\end{definition}

Using information present in Web Ontologies, it may be possible to provide event-based views into entity-based data.

\section{Thoughts on scaling up to handle massive triplestores}

There are several drawbacks with the current implementation that prevent it from being used with massive triplestores.
In the worst case, some of the functions would require reading in a significant amount of data from the triplestore in order to return a value.  One example of this is in the membership functions.

In addition to this, the semantics as they exist currently in some cases perform many small queries to the triplestore, slowing down processing dramatically.
In particular, as seen in the Timing chapter, running time of the semantics was empirically measured to be dominated by the IO involved in actually communicating
with the remote triplestore.

An example of where these small queries are made are in the \texttt{make\_trans\_active'} and \texttt{make\_trans\_passive'} semantic functions.

In these functions, \texttt{getts\_entevprop} is applied to each event list inside the FDBR passed to the function for each preposition's properties.  \texttt{getts\_entevprop} makes a request to the remote triplestore for each event list.  Therefore, if there are $n$ FDBR-pairs inside the FDBR, and
$m$ prepositions, $n*m$ requests will be made to the remote triplestore in the worst case.

\subsection{Query fusion}

One way of remedying this is to reduce the number of queries to the remote triplestore.  To achieve this, it may be possible to modify the semantics to
support {\em query fusion}, fusing smaller queries together into larger queries in order to reduce the number of queries performed.

In the {\em Parser Combinators} chapter of this Thesis Report, it was explained that the parser now operates in the IO monad, and that with a small amount of work, it could
work in other monads as well.  To support query fusion in the semantics, a new monad could be devised that the semantic functions would use instead of the IO monad.  Let us
call this hypothetical monad \texttt{QueryFusion}.  This monad would be pure, functioning much like the monad \texttt{State} as it exists in the Haskell language currently: threading an implicit {\em state} argument through the combinators and semantic functions and keeping the details of that state neatly abstracted away.  The goal of this would be to obtain a value of type \texttt{QueryFusion a}, which with the help of a function, say, \texttt{runQueryFusion}, that would convert the query into an IO action.

One nice side effect of this is that it would allow the semantics to once again be defined as pure functions.

An example of how this could work:

\begin{code}
	
runQueryFusion :: QueryFusion a -> IO a

main = do
  rawQuery <- getQueryString      -- rawQuery :: String
  let sQuery = genQuery rawQuery  -- sQuery   :: QueryFusion Result
  result <- runQueryFusion query  -- result   :: Result
  print result

\end{code}

The actual optimization itself would occur in the \texttt{runQueryFusion} function.  A variety of transformations could occur in this process.

A basic form of query fusion exists in the Solarman source code currently that relies on {\em memoization}.  The SPARQL backend in the Getts module remembers the
results of previous queries, and so if another query is made for the same information, the previous result is returned.  This optimization was made
under the assumption that the triples in the triplestore would not change in the span of time that the query was being made.  More sophisticated query fusions
would be implementable with the above scheme.

\subsection{Data parallelism}

Assuming that the Query Fusion changes are implemented, further optimizations could occur by exploiting parallelism within the semantic functions.
Currently, no parallelism is taken advantage of within the semantics, as they are implemented in a single-threaded manner.

\begin{definition}[Task parallelism]
	Dividing a problem into independent {\em tasks} and executing them in parallel, possibly on different sets of data
\end{definition}

Semantic functions which do not depend on one another, for example \texttt{moon} and \texttt{planet}, could be evaluated in parallel to accelerate processing.
In addition to this, when the final FDBRs are obtained for the semantic functions, {\em data parallelism} could be used to efficiently perform operations
on FDBRs.

\begin{definition}[Data parallelism]
	A special case of task parallelism where the tasks are identical, but are executed over different sets of data
\end{definition}

As an example of data parallelism, consider the problem of squaring each integer in a list. Let us define a function \texttt{square} that computes the square of a number.

\begin{code}
	square :: Integer -> Integer
	square x = x * x
\end{code}

A single-threaded Haskell program might evaluate \texttt{square} across all of the elements in a list in the following manner:

\begin{code}
	list :: [Integer]
	
	squareList = map square
	
	> squareList [1,2,3] => [1,4,9]
\end{code}

Note that squaring one number in the list does not depend on the square of any other number in the list.
Therefore, we could in theory compute the elements of \texttt{squareList [1,2,3]} in parallel.

Suppose we have $n$ hardware threads of execution available to use.  Let us define a function to partition \texttt{list} into $n$ sublists:

\begin{code}
  partition n = foldr buildPart (empty n) . split n
	
  split n [] = []
  split n list = (take n list) : (split n \$ drop n list )
	
  empty 0 = []
  empty n = [] : (empty (n - 1))
	
  buildPart x partition
    = (zipWith (:) x partition) ++ drop (length x) partition
	
\end{code}

Now, execute \texttt{square} over each sublist with a hypothetical \texttt{parMap} function which
performs a \texttt{map} across each element in a list in parallel, distributing each task among a different core:

\begin{code}
	result = concat $ parMap squareList $ partition n list
\end{code}

In this view, \texttt{squareList} is a task being executed in parallel across all of the partitions of our input list.
Specifically, this example is exhibiting data parallelism, as we have one task \texttt{squareList} that is being executed
over different sets of data.  The \texttt{concat} function merges the results back into one list.

One benefit of data parallelism is that it maps well onto a variety of different compute architectures, such as
FPGAs, GPUs, and compute clusters.  In massive triplestores, it may not be feasible to perform computations on
FDBRs in a reasonable amount of time using only single-threaded semantics, as in these triplestores,
an FDBR could contain millions of FDBR-pairs.  Fortunately, each FDBR-pair exists independent of other FDBR-pairs, and 
the semantic functions could be rewritten in a data-parallel way similar to how the above example was rewritten
in order to scale across the available hardware threads in a system.  In doing so, the door would be open for implementing
the semantics on GPUs as well.


\subsection{Conceptual spaces}

One promising approach in processing large amounts of data is Conceptual Spaces\cite{gardenfors2004conceptual}, which has already seen some use in performing queries in the Semantic Web\cite{wu2006exploring}\cite{adams2009conceptual}\cite{gardenfors2014geometry} .  It may be possible to develop a new event-based semantics that uses Conceptual Spaces, and by extension Conceptual Geometry, to perform queries on larger datasets.

\end{document}