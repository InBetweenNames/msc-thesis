\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter{The Query Program}

\label{chapter:implementation}

\section{Data representation}

Like the original Haskell implementations, we represent sets in our implementation using lists and binary relations as association lists.  We represent triples using 3-tuples and we represent URIs using the \texttt{String} type, which is a list of \texttt{Char}.

\section{Structure}

A graph representing the structure of the modules in the XSaiga package in relation to one another is presented in Figure \ref{fig:modulegraph}.  Briefly, there exists an arrow from module \texttt{A} to module \texttt{B} in the graph if and only if module \texttt{A} imports module \texttt{B} in the source code.

\begin{figure}[h]
	\centering
	\frame{\includegraphics[width=\columnwidth]{modules2}}
	\caption{Module graph of the XSaiga package}
	\label{fig:modulegraph}
\end{figure}


\section{AGParser2 and TypeAg2 modules}
\label{section:nonrefparserimpl}

The parser is defined in the \texttt{AGParser2} module.

\begin{figure}[h]
	\centering
	\frame{\includegraphics[width=\textwidth]{semanticsslide3}}
	\caption{Parser operation: how an English sentence is mapped to semantic functions for evaluation\cite{graphmqslide}}
\end{figure}

The types of the semantic functions in \texttt{SolarmanTriplestore} are defined in the TypeAg2 module.
These are the implementations of the semantic functions described in Chapter \ref{chapter:semantics}.
The TypeAg2 module therefore serves as the interface between the parser and the semantics.

The changes made to the original parser to accommodate monadic code are summarized below:

\subsection{PrettyPrinting}
Utility functions for formatting the parser results had to be modified.

\subsubsection{Pure version}
In the pure version, we have:

\begin{code}
class PP' a where
pp' :: a -> Doc
\end{code}

where \texttt{Doc} is a formatted \texttt{String} and instances are defined for the various types
used by the parser itself.

\subsubsection{Monadic version}

In the monadic version, we have:

\begin{code}
class PP' a where
pp' :: a -> IO Doc
\end{code}

Here, the \texttt{pp'} function returns an IO action rather than a pure value.
All instances of \texttt{PP'} were modified accordingly.

\subsection{formatAttsFromAlt}

\subsubsection{Pure version}
\begin{code}
formatAttsFinalAlt  key e t  =
[(pp' [vcat [(vcat [vcat [vcat [text (show ty1v1)  |ty1v1<-val1]
|(((st,inAtt2),(end,synAtts)), ts)<-rs, end == e]                             
| ((i,inAt1),((cs,ct),rs)) <- sr ])
| (s,sr) <- t, s == key ] 

\end{code}

\subsubsection{Monadic version}
\begin{code}
formatAttsFinalAlt  key e t  =
sequence [(sequence [liftM vcat $ sequence
[(liftM vcat $ sequence
[liftM vcat $ sequence
[liftM vcat $ sequence
[liftM text (showio ty1v1) | ty1v1<-val1]
|(id1,val1)<-synAtts]] )
|(((st,inAtt2),(end,synAtts)), ts)<-rs, end == e]
| ((i,inAt1),((cs,ct),rs)) <- sr ])>>= pp'
| (s,sr) <- t, s == key ]
\end{code}

\section{Main module}

The \texttt{Main} module implements a CGI interface for evaluating Natural Language queries using the \texttt{SolarmanTriplestore} module.

\section{Interactive module}

The \texttt{Interactive} module is used by the Direct Query Interface to directly evaluate semantic functions.  It is intended to be used with SafeHaskell
in order to restrict the evaluation of functions to a trusted subset, suitable for online interfaces.

In \texttt{SolarmanTriplestore}, a dictionary is defined that maps words to semantic functions.  This module defines variables that are named
after those words such that those functions can be directly accessed in a Haskell interpreter.  This enables, for instance,

\begin{code}
hall $ discovered phobos
\end{code}

to be directly evaluated at a Haskell prompt.

A Haskell file InteractiveGenerator.hs is used to generate this module using the dictionary in \texttt{SolarmanTriplestore}.

\section{LocalData module}

This module contains an in-program version of the triplestore located on our SPARQL endpoint.  As the \texttt{Getts} module provides
a general interface to triplestores in the form of a typeclass, we are able to support both in-program triplestores as well as remote triplestores.
The module exports the list of triples as the variable \texttt{localData}:

\begin{code}
localData = [("event1000", "object", "sol"),
("event1000", "subject", "mercury"),
("event1000", "type", "orbit_ev"),
("event1001", "object", "sol"),
("event1001", "subject", "venus"),
("event1001", "type", "orbit_ev"),
("event1002", "object", "sol"),
("event1002", "subject", "earth"),
("event1002", "type", "orbit_ev"),
("event1003", "object", "sol"),
... ]
\end{code}

\section{SolarmanTriplestore and Getts modules}

The implementation of our semantics in Haskell is contained within these modules, along with the parser constructed as an executable attribute grammmar and
the dictionary used by the parser.  We detail our implementation improvements over EV-FLMS in Section \ref{section:improvementsimpl}.

\section{Improvements over Original Haskell Implementations}
\label{section:improvementsimpl}

\subsection{Type safety}

The original semantics were implemented as {\em pure functions} in Haskell, which was acceptable for the in-program triplestores they were used on.

In \cite{agboola2015extensible}, the \texttt{getts\_*} functions were modified to retrieve triples from external SPARQL endpoints, enabling the original
semantics to work with SPARQL triplestores.  For SPARQL triplestores, however, the \texttt{getts\_*} functions as defined in \cite{agboola2015extensible} are not actually guaranteed to be referentially transparent. In particular, SPARQL triplestores are able to change over time with triples being potentially added, removed, or modified.
For example, consider the query ``which people discovered a moon that was discovered by a person''.
``people'' and ``person'' are synonyms in our semantics and therefore the same query would be performed twice.  If the SPARQL triplestore changed in between these evaluations,
then these queries could return different results, violating referential transparency.

The function \texttt{unsafeDupablePerformIO} was used in \cite{agboola2015extensible} to force Haskell to treat the \texttt{getts\_*} functions as pure functions
in order to maintain compatibility with the original semantics. The problem with \texttt{unsafeDupablePerformIO} is that it subverts the type system of Haskell.  Code that is built using it is therefore not on
solid theoretical ground within the constructs of the language, and surprising effects can occur as a result.  The use of \texttt{unsafeDupablePerformIO}, while
legitimate in some cases, is heavily discouraged within the Haskell community\cite{tlmvconsensus}.

In this Thesis, we chose a different approach to handling external triplestore queries by representing the triplestore functions and semantics in terms of {\em monadic functions}.
By expressing the semantics and triplestore functions monadically, we stay safely within the confines of Haskell's type system, avoiding
the need to use \texttt{unsafeDupablePerformIO} in order to perform queries to external triplestores as a result.  Another key benefit of this approach is that it preserves the compositional nature of the original semantics.

The semantics are implemented in the IO monad currently.  However, if other monads were desired, just as with the parser described in Chapter \ref{chapter:combinators}, only minimal changes would be required in order to accommodate other instances of the Monad typeclass.  In Chapter \ref{chapter:futurework}, one potential application of this functionality is discussed.

\subsection{The Getts module: A generic interface to triplestores using a typeclass}

Typeclasses are used in Haskell to enable {\em ad-hoc polymorphism} in the definition of functions in the language.  This can be used
to provide generic interfaces to different types, without callers needing to be aware of the differences between those types.
We used this feature of the language to provide a generic interface for triplestores in the form of typeclass \texttt{TripleStore}.

\texttt{TripleStore m} subsumes the functionality that the \texttt{getts\_*} functions provided in the original semantics.

\begin{code}
class TripleStore m where
getts_1 :: m -> (Event, String, String) -> IO [String]
getts_2 :: m -> (Event, String, String) -> IO [String]
getts_3 :: m -> (Event, String, String) -> IO [String]

getts_fdbr_entevprop_type :: m -> String -> String -> IO FDBR
getts_fdbr_entevprop_type ev_data ev_type entity_type = do
evs <- getts_1 ev_data ("?", "type", ev_type)
getts_fdbr_entevprop ev_data entity_type evs

getts_fdbr_entevprop :: m -> String -> [Event] -> IO FDBR
getts_fdbr_entevprop ev_data entity_type evs = do
pairs <- liftM concat $ mapM (\ev -> do
ents <- getts_3 ev_data (ev, entity_type,"?")
return $ zip ents (repeat ev)) evs
return $ collect pairs

getts_members :: m -> String -> IO FDBR
getts_members ev_data set = do
evs_with_set_as_object <- getts_1 ev_data ("?", "object", set)
evs_with_type_membership <- getts_1 ev_data
("?", "type", "membership")
getts_fdbr_entevprop ev_data "subject" $
intersect evs_with_set_as_object evs_with_type_membership
\end{code}

First and foremost, the \texttt{getts\_*} functions defined in \texttt{TripleStore m} now properly return {\em IO actions}.
Three new functions are introduced: \texttt{getts\_fdbr\_entevprop},\\ \texttt{getts\_fdbr\_entevprop\_type}, and \texttt{getts\_members}.
\texttt{getts\_fdbr\_entevprop\_type} serves the same purpose that \texttt{make\_image} had in the original semantics.
These functions are named after their counterparts in Chapter 3.

Only the three \texttt{getts\_*} functions must be defined for the new type of triplestore at minimum, however efficient implementations
of all functions in the typeclass may be provided if desired.  We provide a backend using a SPARQL endpoint as a triplestore using the
\texttt{SPARQLBackend} type and a backend for in-program triplestores using the \texttt{[Triple]} type as instances of \texttt{TripleStore}.

\subsubsection{Basic query fusion}

In addition to this, a basic form of query fusion has been implemented in the form of memoization.  Briefly, queries and their results
are stored in {\em key-value stores}.  When a query is performed, it is first checked against the appropriate key-value store to see
if the same triplestore query has been made previously.  If it has, the previous result is returned.  Otherwise, the request is made to the remote
triplestore and its result is saved into the appropriate key-value store.  Multiple requests for the same information to the remote triplestore are therefore fused together.

The key-value stores are held in top-level mutable variables.  Defining top-level mutable variables in Haskell is a subject that has been explored in depth, with many proposals in how to provide an idiomatic method in the language to express it.  According to the Haskell community, the accepted way of doing this for now is with the following pattern\cite{tlmvconsensus}:

\begin{itemize}
	\item A top-level mutable variable \texttt{v} is defined using \texttt{v = unsafePerformIO \$ newIORef value} 
	\item \texttt{v} must be annotated with the compiler pragma \texttt{\{\--\# NOINLINE v \#\--\}}
\end{itemize}

\subsubsection{Efficiency of ``collect''}

The \texttt{collect} function as defined in \cite{agboola2015extensible} used a key-value store from the \texttt{Data.Map.Lazy} module in Haskell to efficiently construct Images from relations represented as association lists.  Because all key-value pairs of the \texttt{Map} will be traversed in order, immediately, in all cases, in this Thesis the \texttt{Data.Map.Strict} module was used instead.  The asymptotic time complexity of both methods are identical, however the \texttt{Strict} version uses less memory and is slightly faster as it does not attempt to store partially evaluated areas of the Map as {\em thunks}, which are partially evaluated Haskell expressions.

The \texttt{collect} function is defined in this module as:

\begin{code}
collect = Map.toList . Map.fromListWith (++) . map (\(x, y) -> (x, [y]))
\end{code}

%\begin{theorem}
%	\texttt{collect} is optimal.
%\end{theorem}

%Proof: Suppose a function \texttt{collect'} exists that converts a relation into an Image in faster than O($n$ lg $n$) time.

%Let $unsorted$ be an unsorted list whose list elements are an instance of the \texttt{Comparable} typeclass.
%That is, the list elements can be compared with one another using the comparison operators.

%Define the function \texttt{sort'} as follows:

%\begin{code}
%	sort' = uncollect . collect'
%	where
%	uncollect = map (\(ent, evs) -> map (\ev -> (ent, ev)) evs)
%\end{code}

\subsubsection{Efficiently constructing FDBRs from grouped association lists}
In addition, a new function, \texttt{condense}, has been created to efficiently construct $FDBR(r)$ such that $r$ is represented by an association list that is grouped according to the first element in each pair.

The \texttt{condense} function is defined in this module as:

\begin{code}
condense =
map (\list -> (fst $ head list, map snd list)) . List.groupBy cmp
where
cmp x y = (fst x) == (fst y)
\end{code}

In our SPARQL backend, the \texttt{getts\_fdbr\_entevprop} and \texttt{getts\_fdbr\_entevprop\_type} functions efficiently construct FDBRs of their ENTEVPROP relations using this function by requesting that the ENTEVPROP query results be sorted according to the first element in each pair.  Since this groups pairs together in the association list by their first element, \texttt{condense} is used instead of \texttt{collect} in order to construct the FDBR in the SPARQL backend.

\begin{theorem}
	\texttt{condense} has $O(n)$ worst-case upper-bound asymptotic time complexity, with comparison on the first element in the association list pairs being the key operation.
\end{theorem}

Proof:

\texttt{cmp} is the function that compares two association list pairs by their first element.  

%\begin{proposition}
%	\texttt{cmp} has $O(1)$ worst-case upper-bound asymptotic time complexity, with comparison being the key operation.
%\end{proposition}

%Proof:

%In the Haskell standard library source code, \texttt{fst} is defined as follows \cite{hstdlib}:

%\begin{code}
%	fst (x,_) = x
%\end{code}

%This function has trivially $\theta(1)$ worst-case tight bound time complexity for any key operation.

%Since Haskell is a pass-by-reference language with lazy evaluation, this function will return in a constant amount of time regardless of the size of \texttt{x},
%as \texttt{x} will not be copied on return of the function.  Therefore \texttt{fst} has $\theta(1)$ worst-case tight bound time complexity.

%The operator \texttt{(==)} for the \texttt{String} type (triples are represented as 3-tuples of \texttt{Strings} in our code) has a worst-case upper bound time %complexity of O$(n)$, because in the worst case, both \texttt{Strings} being compared have length $n$ and are equal, forcing each character in both strings to be %evaluated and compared.

%Only one comparison on the first elements of the pairs \texttt{x} and \texttt{y} is performed for \texttt{cmp x y}.
%Therefore, the worst-case upper-bound asymptotic time complexity of \texttt{cmp} is O$(1)$.

%Since the $O(n)$ term dominates for large $n$, \texttt{cmp} therefore has a worst-case tight-bound asymptotic time complexity of $O(n)$. \qedsymbol

\begin{proposition}
	The function \texttt{List.groupBy cmp} has O$(n)$ worst-case upper-bound asymptotic time complexity, with comparisons on the elements of the input list using \texttt{cmp} being the key operation.
\end{proposition}

Proof:

In the Haskell standard library source code, \texttt{Data.List.groupBy} is defined as follows\cite{hstdlib}:

\begin{code}
groupBy _  []           =  []
groupBy eq (x:xs)       =  (x:ys) : groupBy eq zs
where (ys,zs) = span (eq x) xs
\end{code}

\texttt{span} is defined as follows\cite{hstdlib}:

\begin{code}
span _ xs@[]            =  (xs, xs)
span p xs@(x:xs')
| p x          =  let (ys,zs) = span p xs' in (x:ys,zs)
| otherwise    =  ([],xs)
\end{code}

%\begin{subproposition}
%	\texttt{span} has O$(n)$ worst case tight bound asymptotic time complexity, with evaluations of predicate \texttt{p} being the key operation.
%\end{subproposition}

%Proof:

%In the worst case, \texttt{p} will evaluate to \texttt{True} for all elements in the input list \texttt{xs}, forcing
%the evaluation of \texttt{span} on all suffixes of \texttt{xs}.  Since there are $n + 1$ suffixes of \texttt{xs}, 
%and \texttt{p} is evaluated for each suffix, it follows that $n + 1$ evaluations of \texttt{p} are performed.
%Therefore, \texttt{span} has a worst-case lower-bound asymptotic time complexity of O$(n + 1) = $O$(n)$. \qedsymbol

%--

Here, \text{eq = cmp} in \texttt{groupBy}, with \texttt{eq x = cmp x = p} being the predicate function used in \texttt{span}. %for elements of the list \text{(x:xs)}.

%The $0$th contiguous group of elements in a list \texttt{qs} according to a predicate \texttt{pred} is the longest prefix \texttt{pre} of \texttt{qs} where
%\texttt{pred} is \texttt{True} for all elements in \texttt{pre}.

%The $i$th contiguous group of elements in a list \texttt{qs} according to a predicate \texttt{pred} is the $0$th contiguous group of elements of
%the list obtained by removing all previous contiguous groups of elements from \texttt{qs}. 

%The $i$th contiguous group of elements in a list \texttt{qs} according to a predicate \texttt{pred} is the longest prefix \texttt{pre} of the list \texttt{rs}
%where \texttt{rs} is the list obtained by removing all previous contiguous groups of elements from \texttt{qs}, and \texttt{pred} is \texttt{True} for all elements
%of \texttt{pre}.

%A contiguous group of elements in a list \texttt{qs} under a predicate \texttt{pred} is a contiguous sublist of \texttt{qs} such that \texttt{pred}
%is \texttt{True} for all elements in the sublist.

%Let $m$ be the number of contiguous groups of elements in the list \texttt{(x:xs)}.

%Let $C$ be the list containing the number of elements in each contiguous group of elements in the list \texttt{(x:xs)}.  \texttt{C[i]} denotes the \texttt{i}th element in \texttt{C}.

Let $n$ denote the number of elements in \texttt{(x:xs)}.

The function \texttt{span} returns a partition \texttt{(ys, zs)} of the input list \texttt{xs}, where \texttt{ys} is the longest prefix of \texttt{xs} such that predicate \texttt{p} is \texttt{True} on all elements in the prefix, and \texttt{zs} are the remaining elements in \texttt{xs}.  It follows that \texttt{p} is evaluated at least $s$ times and at most $s + 1$ times, where $s$ is the length of \texttt{pre} (it will only be evaluated $s$ times if \texttt{pre = xs}).

By recursing into the second list returned by \texttt{span}, no previous elements of \texttt{(x:xs)} are revisited, and no elements are skipped, so \texttt{groupBy} partitions the input list \texttt{(x:xs)} into $m$ lists.  Call this partition \texttt{part}.  Note that the sum of the lengths of all lists in \texttt{part} is $n$.

For each list \texttt{i} in \texttt{part} except the last, \texttt{(length i - 1) + 1 = length i} comparisons will have been made (\texttt{groupBy} calls span on \texttt{xs}, not \texttt{x:xs}).  For the last list $last$ in \texttt{part}, \texttt{(length last - 1)} comparisons will have been made (the longest prefix is \texttt{xs} in this case).  Therefore, the total number of comparisons made can be expressed by:

\begin{code}
length part[0] + length part[1] + ... + length part[m - 2]
  + (length part[m - 1] - 1)
= (length part[0] + length part[1] + ... + length part[m - 1]) - 1
= n - 1
\end{code}

Hence, the worst-case upper-bound asymptotic time complexity of \texttt{List.groupBy cmp} is O$(n - 1)$ = O$(n)$, with comparisons using \texttt{cmp} being the key operation.
\qedsymbol

--

The lambda provided to \texttt{map} performs no comparisons and therefore has a worst-case tight-bound time complexity of
$\theta(1)$ with comparisons being the key operation.

The same applies to the composition function $\circ$.

--

%Let \texttt{groupPair list = (fst \$ head list, map snd list)}.

%\begin{proposition}
%	groupPair has O$(n)$ time complexity
%\end{proposition}

%Proof:

%\texttt{head list} has a worst-case tight-bound time complexity of $\theta(1)$.

%\texttt{snd} has a worst-case tight-bound time complexity of $\theta(1)$.

%\texttt{map} evaluates \texttt{snd} on every element of \texttt{list}, with
%a worst-case tight-bound time complexity of $\theta(n)*\theta(1) = \theta(n)$ .
%--

%\texttt{groupPair} and the lambda used in \texttt{map} used above have an identical definition and therefore have
%the same asymptotic time complexity.

The \texttt{map} function is composed with the \texttt{List.groupBy cmp} function to produce a new function:
\begin{code}
\x -> map (\list -> (fst $ head list, map snd list))
(List.groupBy cmp x)
\end{code}

The \texttt{map} function evaluates the lambda over every list in the partition returned by (List.groupBy cmp x).  Since
neither the map, the lambda, nor the function composition perform any comparisons, they do not contribute to the number
of key operations performed.

Therefore the worst-case upper bound time complexity of \texttt{condense} is \[O(1) + n*(O(1) + O(1)) + O(n) = O(n)\] with comparison on the first element in
the association list pairs (\texttt{cmp}) being the key operation.
$\blacksquare$

%Since \texttt{condense} has a worst-case tight bound asymptotic time complexity of $\theta(n)$, it is optimal. \qedsymbol 


\section{Summary}

In this Chapter we presented an overview of our query program structure as well as how we efficiently implemented our semantics in Haskell.
We showed the modifications we made to the parser described in \cite{frosthafiz2008} in order to accommodate monadic functions as attributes.
We presented a basic form of query fusion as used by our implementation, and showed an improved version of \texttt{collect} for
grouped association lists.  In Chapter \ref{chapter:timing}, we perform some benchmarks to measure the empirical performance of our code.



\end{document}
